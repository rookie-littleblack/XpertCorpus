# ç®¡é“å±‚ API æ–‡æ¡£

ç®¡é“å±‚ä¸º XpertCorpus æä¾›å¤šç®—å­ç¼–æ’åŠŸèƒ½ï¼Œå®ç°å¤æ‚çš„æ•°æ®å¤„ç†æµç¨‹ã€‚

## æ¨¡å—æ¦‚è¿°

ç®¡é“å±‚ä½äºæ¡†æ¶å±‚å’Œç®—å­å±‚ä¹‹é—´ï¼Œä¸“æ³¨äºå°†å¤šä¸ªç®—å­ç»„åˆæˆæœ‰åºçš„å¤„ç†æµç¨‹ã€‚æ¯ä¸ªç®¡é“éƒ½ç»§æ‰¿è‡ª `PipelineABC`ï¼Œæä¾›ç»Ÿä¸€çš„æ¥å£å’Œç”Ÿå‘½å‘¨æœŸç®¡ç†ã€‚

## è®¾è®¡ç†å¿µ

### èŒè´£å®šä½
- **ç®—å­ç¼–æ’**ï¼šå°†å¤šä¸ªåŸå­æ“ä½œç»„åˆæˆå®Œæ•´çš„å¤„ç†æµç¨‹
- **æµç¨‹æ§åˆ¶**ï¼šç®¡ç†æ•°æ®åœ¨ä¸åŒç®—å­é—´çš„æµè½¬
- **å¹¶è¡Œåè°ƒ**ï¼šæ”¯æŒå¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†
- **çŠ¶æ€ç®¡ç†**ï¼šè·Ÿè¸ªç®¡é“æ‰§è¡ŒçŠ¶æ€å’Œæ€§èƒ½æŒ‡æ ‡

### æ¶æ„å±‚æ¬¡
```
FrameworkABC (æ¡†æ¶å±‚) - å®Œæ•´ä¸šåŠ¡æµç¨‹
    â†“
PipelineABC (ç®¡é“å±‚) - å¤šç®—å­ç¼–æ’ â† å½“å‰å±‚
    â†“  
OperatorABC (ç®—å­å±‚) - å•ä¸€åŠŸèƒ½å®ç°
```

## ç°æœ‰ç®¡é“

### ğŸ§¹ [æ–‡æœ¬æ¸…æ´—ç®¡é“ (xcleaning_pipe)](xcleaning_pipe.md)
ä¸“ç”¨äºæ–‡æœ¬æ¸…æ´—çš„å¤„ç†ç®¡é“ã€‚

**æ ¸å¿ƒç‰¹æ€§ï¼š**
- é›†æˆå¤šç§æ–‡æœ¬æ¸…æ´—å¾®æ“ä½œ
- æ”¯æŒå¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†
- è¡¨æƒ…ç¬¦å·å’Œemojiç§»é™¤
- å¯é…ç½®çš„å¤„ç†é™åˆ¶

**ä½¿ç”¨åœºæ™¯ï¼š**
- åŸå§‹æ–‡æœ¬æ•°æ®é¢„å¤„ç†
- ç¤¾äº¤åª’ä½“æ–‡æœ¬æ¸…æ´—
- è¯­æ–™åº“æ ‡å‡†åŒ–

**æ€§èƒ½ç‰¹ç‚¹ï¼š**
- å¹¶è¡Œå¤„ç†ï¼Œæ˜¾è‘—æå‡æ€§èƒ½
- æµå¼å¤„ç†ï¼Œå†…å­˜ä½¿ç”¨ç¨³å®š
- é”™è¯¯å®¹é”™ï¼Œå•è¡Œå¤±è´¥ä¸å½±å“æ•´ä½“

## ç®¡é“å¼€å‘æŒ‡å—

### åˆ›å»ºæ–°ç®¡é“

```python
from xpertcorpus.modules.others.xpipeline import PipelineABC, PipelineState, register_pipeline

@register_pipeline("custom_pipeline")
class CustomPipeline(PipelineABC):
    """è‡ªå®šä¹‰å¤„ç†ç®¡é“"""
    
    VERSION = "1.0.0"
    
    def _configure_operators(self):
        """é…ç½®ç®¡é“ä¸­çš„ç®—å­"""
        self.add_operator(RemoveEmoticonsMicroops())
        self.add_operator(RemoveEmojiMicroops())
        self.add_operator(RemoveExtraSpacesMicroops())
    
    def get_desc(self, lang="zh"):
        """è·å–ç®¡é“æè¿°"""
        return "è‡ªå®šä¹‰æ•°æ®å¤„ç†ç®¡é“"
    
    def run(self, storage, input_key="raw_content", output_key=None):
        """æ‰§è¡Œç®¡é“å¤„ç†"""
        try:
            self.state = PipelineState.RUNNING
            
            # æ•°æ®å¤„ç†é€»è¾‘
            dataframe = storage.read('dataframe')
            
            # åº”ç”¨æ‰€æœ‰ç®—å­
            for operator in self.operators:
                # å¤„ç†é€»è¾‘
                pass
            
            # ä¿å­˜ç»“æœ
            storage.write(dataframe)
            self.state = PipelineState.COMPLETED
            
            return output_key
            
        except Exception as e:
            self.state = PipelineState.FAILED
            raise
```

### æœ€ä½³å®è·µ

#### 1. ç®—å­ç»„ç»‡
```python
# âœ… æ¨èï¼šç›¸å…³åŠŸèƒ½çš„ç®—å­ç»„åˆ
class TextNormalizationPipeline(PipelineABC):
    def _configure_operators(self):
        self.add_operator(RemoveEmoticonsMicroops())
        self.add_operator(RemoveEmojiMicroops())
        self.add_operator(RemoveExtraSpacesMicroops())

# âŒ ä¸æ¨èï¼šæ— å…³åŠŸèƒ½æ··åˆ
class EverythingPipeline(PipelineABC):
    def _configure_operators(self):
        self.add_operator(RemoveEmoticonsMicroops())  # æ–‡æœ¬æ¸…æ´—
        self.add_operator(SomeImageProcessor())       # âŒ å›¾åƒå¤„ç† - èŒè´£ä¸ç›¸å…³
        self.add_operator(SomeDatabaseQuery())        # âŒ æ•°æ®åº“æŸ¥è¯¢ - èŒè´£ä¸ç›¸å…³
```

#### 2. çŠ¶æ€ç®¡ç†
```python
def run(self, storage, input_key, output_key):
    start_time = datetime.now()
    
    try:
        # è®¾ç½®è¿è¡ŒçŠ¶æ€
        self.state = PipelineState.RUNNING
        self.metrics["execution_count"] += 1
        
        # å¤„ç†é€»è¾‘
        result = self._process_data(storage, input_key, output_key)
        
        # æ›´æ–°æŒ‡æ ‡
        execution_time = (datetime.now() - start_time).total_seconds()
        self.metrics["total_processing_time"] += execution_time
        self.metrics["last_execution_time"] = execution_time
        
        # è®¾ç½®å®ŒæˆçŠ¶æ€
        self.state = PipelineState.COMPLETED
        return result
        
    except Exception as e:
        # é”™è¯¯å¤„ç†
        self.state = PipelineState.FAILED
        self.metrics["error_count"] += 1
        raise
```

#### 3. å¹¶è¡Œå¤„ç†
```python
from concurrent.futures import ThreadPoolExecutor

def run(self, storage, input_key, output_key):
    # å‡†å¤‡æ•°æ®
    items = list(dataframe.iterrows())
    
    def process_item(row):
        content = row[1].get(input_key, '')
        # åº”ç”¨æ‰€æœ‰ç®—å­
        for operator in self.operators:
            content = operator.run(content)
        return content
    
    # å¹¶è¡Œå¤„ç†
    with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
        results = list(executor.map(process_item, items))
    
    return results
```

## é…ç½®ç³»ç»Ÿ

### ç®¡é“é…ç½®
```python
# åˆ›å»ºé…ç½®
config = {
    "batch_size": 1000,
    "enable_logging": True,
    "operator_configs": {
        "first_op": {"param1": "value1"},
        "second_op": {"param2": "value2"}
    }
}

# ä½¿ç”¨é…ç½®
pipeline = CustomPipeline(
    max_workers=4,
    limit=50000,
    config=config
)
```

### åŠ¨æ€é…ç½®
```python
class ConfigurablePipeline(PipelineABC):
    def _configure_operators(self):
        # æ ¹æ®é…ç½®åŠ¨æ€æ·»åŠ ç®—å­
        if self.config.get("enable_cleaning", True):
            self.add_operator(CleaningMicroops())
        
        if self.config.get("enable_normalization", False):
            self.add_operator(NormalizationMicroops())
        
        # å¯é€‰çš„é«˜çº§ç®—å­
        if self.config.get("enable_advanced", False):
            self.add_operator(AdvancedMicroops())
```

## æ€§èƒ½ä¼˜åŒ–

### å¹¶è¡Œå¤„ç†ç­–ç•¥
- **CPUå¯†é›†å‹**ï¼šè®¾ç½® `max_workers = cpu_count - 1`
- **IOå¯†é›†å‹**ï¼šè®¾ç½® `max_workers = cpu_count * 2`
- **å†…å­˜é™åˆ¶**ï¼šä½¿ç”¨ `limit` å‚æ•°åˆ†æ‰¹å¤„ç†

### å†…å­˜ç®¡ç†
```python
# å¤§æ•°æ®é›†å¤„ç†
pipeline = CustomPipeline(
    max_workers=4,
    limit=10000,  # åˆ†æ‰¹å¤„ç†
    config={
        "use_streaming": True,
        "buffer_size": 1000
    }
)
```

## é”™è¯¯å¤„ç†

### å®¹é”™è®¾è®¡
```python
def process_item(self, item):
    try:
        # å¤„ç†å•ä¸ªé¡¹ç›®
        for operator in self.operators:
            item = operator.run(item)
        return item
    except Exception as e:
        # è®°å½•é”™è¯¯ä½†ç»§ç»­å¤„ç†
        xlogger.error(f"Error processing item: {e}")
        return item  # è¿”å›åŸå§‹æ•°æ®
```

### ç®¡é“çº§é”™è¯¯
```python
def run(self, storage, input_key, output_key):
    try:
        # ç®¡é“å¤„ç†é€»è¾‘
        return self._execute_pipeline(storage, input_key, output_key)
    except Exception as e:
        # ç®¡é“çº§é”™è¯¯å¤„ç†
        self.state = PipelineState.FAILED
        self.metrics["error_count"] += 1
        xlogger.error(f"Pipeline {self.__class__.__name__} failed: {e}")
        raise
```

## ç›‘æ§å’Œè°ƒè¯•

### æ€§èƒ½ç›‘æ§
```python
# è·å–ç®¡é“æ€§èƒ½ä¿¡æ¯
metrics = pipeline.get_metrics()
print(f"æ‰§è¡Œæ¬¡æ•°: {metrics['execution_count']}")
print(f"å¹³å‡æ‰§è¡Œæ—¶é—´: {metrics['average_execution_time']:.2f}s")
print(f"é”™è¯¯æ¬¡æ•°: {metrics['error_count']}")
```

### çŠ¶æ€è·Ÿè¸ª
```python
# æ‰§è¡Œå‰æ£€æŸ¥
print(f"æ‰§è¡Œå‰çŠ¶æ€: {pipeline.get_state()}")

# æ‰§è¡Œå¤„ç†
result = pipeline.run(storage)

# æ‰§è¡Œåæ£€æŸ¥
print(f"æ‰§è¡ŒåçŠ¶æ€: {pipeline.get_state()}")
if pipeline.get_state() == PipelineState.COMPLETED:
    print("ç®¡é“æ‰§è¡ŒæˆåŠŸ")
```

## æ‰©å±•æ€§

### ç®—å­æ‰©å±•
```python
class ExtendedPipeline(XCleaningPipe):
    """æ‰©å±•ç°æœ‰ç®¡é“"""
    
    def _configure_operators(self):
        # ä¿ç•™åŸæœ‰ç®—å­
        super()._configure_operators()
        
        # æ·»åŠ æ–°ç®—å­
        self.add_operator(RemoveExtraSpacesMicroops())
```

### é…ç½®æ‰©å±•
```python
# æ”¯æŒæ›´å¤šé…ç½®é€‰é¡¹
extended_config = {
    "text_cleaning": {
        "remove_emoticons": True,
        "remove_emojis": True,
        "remove_extra_spaces": True
    },
    "performance": {
        "parallel_processing": True,
        "batch_size": 5000,
        "max_workers": 8
    }
}
```

## ç›¸å…³æ–‡æ¡£

- [ç®¡é“åŸºç±» (xpipeline)](../others/xpipeline.md) - ç®¡é“æŠ½è±¡åŸºç±»æ–‡æ¡£
- [ç®—å­åŸºç±» (xoperator)](../others/xoperator.md) - ç®—å­æŠ½è±¡åŸºç±»æ–‡æ¡£
- [å¾®æ“ä½œæ¨¡å— (microops)](../microops/) - å¾®æ“ä½œå®ç°æ–‡æ¡£
- [æ¡†æ¶ç³»ç»Ÿ (frameworks)](../frameworks/) - æ¡†æ¶å±‚æ–‡æ¡£

---

[è¿”å› API æ–‡æ¡£é¦–é¡µ](../README.md) 