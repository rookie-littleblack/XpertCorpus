# é¢„è®­ç»ƒæ¡†æž¶ (xframe_pt)

`xpertcorpus.modules.frameworks.xframe_pt` æ¨¡å—æä¾›äº†ä¸“ç”¨äºŽé¢„è®­ç»ƒæ•°æ®ç”Ÿæˆçš„ç«¯åˆ°ç«¯æ¡†æž¶ã€‚

## æ¦‚è¿°

XFramework_PT æ˜¯ XpertCorpus çš„æ ¸å¿ƒæ¡†æž¶ä¹‹ä¸€ï¼Œä¸“é—¨ç”¨äºŽå¤„ç†åŽŸå§‹è¯­æ–™å¹¶ç”Ÿæˆé«˜è´¨é‡çš„é¢„è®­ç»ƒæ•°æ®ã€‚è¯¥æ¡†æž¶é›†æˆäº†æ–‡æœ¬æ¸…æ´—ã€æ ¼å¼è½¬æ¢ã€æ™ºèƒ½åˆ†å‰²ç­‰å®Œæ•´çš„å¤„ç†é“¾è·¯ã€‚

### æ ¸å¿ƒç‰¹æ€§

- **ðŸ—‚ï¸ åŽŸå§‹è¯­æ–™å¤„ç†** - æ”¯æŒä»Žæ–‡æœ¬ç›®å½•åˆ°JSONLçš„è‡ªåŠ¨è½¬æ¢
- **ðŸ¤– LLMé©±åŠ¨æ¸…æ´—** - åŸºäºŽå¤§è¯­è¨€æ¨¡åž‹çš„æ™ºèƒ½æ–‡æœ¬æ¸…æ´—
- **ðŸ”„ å¤šé˜¶æ®µç®¡é“** - æ¸…æ´—ã€è¿‡æ»¤ã€åˆ†å‰²çš„å®Œæ•´å¤„ç†æµç¨‹
- **ðŸ“Š è´¨é‡ä¿è¯** - å†…ç½®æ•°æ®éªŒè¯å’Œè´¨é‡æ£€æµ‹
- **âš¡ é«˜æ€§èƒ½å¤„ç†** - å¤šçº¿ç¨‹å¹¶å‘å’Œæµå¼å¤„ç†æ”¯æŒ
- **ðŸ§  æ™ºèƒ½çŠ¶æ€ç®¡ç†** - è‡ªåŠ¨çŠ¶æ€æ£€æµ‹å’Œç®¡é“å‡†å¤‡
- **ðŸ”§ é…ç½®é©±åŠ¨** - çµæ´»çš„é…ç½®ç³»ç»Ÿå’Œç»„ä»¶ç®¡ç†

## ç±»å®šä¹‰

### XFramework_PT

é¢„è®­ç»ƒæ•°æ®ç”Ÿæˆæ¡†æž¶çš„ä¸»ç±»ã€‚

```python
@register_framework("pretraining")
class XFramework_PT(FrameworkABC):
    """é¢„è®­ç»ƒæ•°æ®ç”Ÿæˆæ¡†æž¶"""
    
    # æ¡†æž¶å…ƒæ•°æ®
    FRAMEWORK_TYPE = FrameworkType.PRETRAINING
    VERSION = "1.0.0"
    REQUIRED_OPERATORS = ["llm_cleaner", "text_splitter"]
    REQUIRED_PIPELINES = ["cleaning_pipe"]
```

#### æž„é€ æ–¹æ³•

```python
def __init__(self, 
             input_file: str, 
             output_dir: str = "./output", 
             max_workers: int = 1, 
             limit: int = 0,
             config: Optional[Dict[str, Any]] = None):
    """
    åˆå§‹åŒ–é¢„è®­ç»ƒæ¡†æž¶ã€‚

    Args:
        input_file: è¾“å…¥æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„
        max_workers: å·¥ä½œçº¿ç¨‹æ•°
        limit: å¤„ç†é™åˆ¶ï¼ˆ0è¡¨ç¤ºæ— é™åˆ¶ï¼‰
        config: å¯é€‰é…ç½®å­—å…¸

    Examples:
        >>> # å¤„ç†åŽŸå§‹æ–‡æœ¬ç›®å½•
        >>> framework = XFramework_PT(
        ...     input_file="corpus_directory/",
        ...     output_dir="./output",
        ...     max_workers=4
        ... )
        
        >>> # å¤„ç†JSONLæ–‡ä»¶
        >>> framework = XFramework_PT(
        ...     input_file="data.jsonl",
        ...     output_dir="./output"
        ... )
    """
```

## é…ç½®ç³»ç»Ÿ

XFramework_PT æ”¯æŒä¸°å¯Œçš„é…ç½®é€‰é¡¹ï¼Œé‡‡ç”¨å±‚æ¬¡åŒ–ç»“æž„ï¼š

### é»˜è®¤é…ç½®

```python
default_config = {
    # æ–‡æœ¬åˆ†å‰²å™¨é…ç½®
    "text_splitter": {
        "chunk_size": 512,                    # åˆ†å—å¤§å°
        "chunk_overlap": 200,                 # é‡å é•¿åº¦
        "split_method": "markdown",           # åˆ†å‰²æ–¹æ³•ï¼šmarkdown/semantic
        "min_tokens_per_chunk": 20           # æœ€å°ä»¤ç‰Œæ•°
    },
    
    # LLMæ¸…æ´—å™¨é…ç½®
    "llm_cleaner": {
        "enable_token_tracking": True,        # å¯ç”¨ä»¤ç‰Œè¿½è¸ª
        "reset_tokens_on_start": True        # å¼€å§‹æ—¶é‡ç½®ä»¤ç‰Œ
    },
    
    # å­˜å‚¨é…ç½®
    "storage": {
        "enable_compression": False,          # å¯ç”¨åŽ‹ç¼©
        "validate_on_write": True,           # å†™å…¥æ—¶éªŒè¯
        "cache_type": "jsonl"                # ç¼“å­˜ç±»åž‹
    },
    
    # å¤„ç†é…ç½®
    "processing": {
        "auto_detect_raw_corpus": True,      # è‡ªåŠ¨æ£€æµ‹åŽŸå§‹è¯­æ–™
        "supported_extensions": [".txt", ".md"],  # æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å
        "exclude_patterns": [".bak"]         # æŽ’é™¤çš„æ–‡ä»¶æ¨¡å¼
    }
}
```

### é…ç½®ä½¿ç”¨ç¤ºä¾‹

```python
# è‡ªå®šä¹‰é…ç½®
custom_config = {
    "text_splitter": {
        "chunk_size": 1024,
        "split_method": "semantic"
    },
    "storage": {
        "enable_compression": True
    },
    "processing": {
        "supported_extensions": [".txt", ".md", ".rst"]
    }
}

framework = XFramework_PT(
    input_file="corpus/",
    config=custom_config
)
```

## æ ¸å¿ƒæ–¹æ³•

### å¤„ç†æµç¨‹æ–¹æ³•

#### prepare()
å‡†å¤‡æ¡†æž¶ç»„ä»¶ã€‚

```python
def prepare(self) -> 'XFramework_PT':
    """
    å‡†å¤‡æ¡†æž¶æ‰§è¡Œã€‚
    
    åˆå§‹åŒ–æ‰€æœ‰å¿…éœ€çš„ç»„ä»¶ï¼š
    - LLMæ¸…æ´—å™¨
    - æ¸…æ´—ç®¡é“
    - æ–‡æœ¬åˆ†å‰²å™¨
    - é™åˆ¶å™¨ï¼ˆå¦‚æžœè®¾ç½®äº†limitï¼‰
    
    Returns:
        Selfï¼ˆæ”¯æŒæ–¹æ³•é“¾ï¼‰
    
    Raises:
        ValueError: å¦‚æžœå¿…éœ€ç»„ä»¶åˆå§‹åŒ–å¤±è´¥
    """
```

#### run()
æ‰§è¡Œå®Œæ•´çš„å¤„ç†ç®¡é“ã€‚

```python
def run(self) -> Dict[str, Any]:
    """
    æ‰§è¡Œé¢„è®­ç»ƒæ•°æ®ç”Ÿæˆæµç¨‹ã€‚
    
    æ™ºèƒ½çŠ¶æ€ç®¡ç†ï¼š
    - INITIALIZED çŠ¶æ€ï¼šè‡ªåŠ¨è°ƒç”¨ prepare() ç„¶åŽæ‰§è¡Œ
    - CONFIGURED çŠ¶æ€ï¼šç›´æŽ¥æ‰§è¡Œï¼Œæ— éœ€é‡å¤å‡†å¤‡
    - å…¶ä»–çŠ¶æ€ï¼šæŠ›å‡º ValueError
    
    å¤„ç†æ­¥éª¤ï¼š
    1. æ•°æ®é™åˆ¶ï¼ˆå¦‚æžœé…ç½®ï¼‰
    2. LLMæ–‡æœ¬æ¸…æ´—
    3. å¤šé˜¶æ®µæ¸…ç†ç®¡é“
    4. æ™ºèƒ½æ–‡æœ¬åˆ†å‰²
    
    Returns:
        åŒ…å«å¤„ç†ç»“æžœçš„å­—å…¸ï¼š
        {
            "output_path": str,              # è¾“å‡ºè·¯å¾„
            "final_output_key": str,         # æœ€ç»ˆè¾“å‡ºé”®
            "token_usage": dict,             # ä»¤ç‰Œä½¿ç”¨ç»Ÿè®¡
            "storage_stats": dict,           # å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯
            "pipeline_outputs": dict         # å„æ­¥éª¤è¾“å‡º
        }
    
    Raises:
        FileNotFoundError: è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨
        ValueError: è¾“å…¥æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®æˆ–çŠ¶æ€æ— æ•ˆ
    """
```

### ä¿¡æ¯èŽ·å–æ–¹æ³•

#### get_desc()
èŽ·å–æ¡†æž¶æè¿°ã€‚

```python
def get_desc(self, lang: str = "zh") -> str:
    """
    èŽ·å–æ¡†æž¶æè¿°ä¿¡æ¯ã€‚
    
    Args:
        lang: è¯­è¨€ä»£ç ï¼ˆ"zh" æˆ– "en"ï¼‰
    
    Returns:
        æ¡†æž¶æè¿°å­—ç¬¦ä¸²
    """
```

#### get_pipeline_info()
èŽ·å–ç®¡é“è¯¦ç»†ä¿¡æ¯ã€‚

```python
def get_pipeline_info(self) -> Dict[str, Any]:
    """
    èŽ·å–ç®¡é“è¯¦ç»†ä¿¡æ¯ã€‚
    
    Returns:
        åŒ…å«ä»¥ä¸‹ä¿¡æ¯çš„å­—å…¸ï¼š
        {
            "framework_type": str,           # æ¡†æž¶ç±»åž‹
            "version": str,                  # ç‰ˆæœ¬å·
            "is_raw_corpus": bool,           # æ˜¯å¦ä¸ºåŽŸå§‹è¯­æ–™
            "preprocessed_file": str,        # é¢„å¤„ç†æ–‡ä»¶è·¯å¾„
            "components": dict,              # ç»„ä»¶çŠ¶æ€
            "configuration": dict,           # é…ç½®ä¿¡æ¯
            "metrics": dict,                 # æ€§èƒ½æŒ‡æ ‡
            "state": str                     # å½“å‰çŠ¶æ€
        }
    """
```

### å‘åŽå…¼å®¹æ–¹æ³•

#### forward()
ä¼ ç»Ÿæ‰§è¡Œæ–¹æ³•ï¼ˆå·²å¼ƒç”¨ï¼‰ã€‚

```python
def forward(self) -> Dict[str, Any]:
    """
    ä¼ ç»Ÿçš„æ‰§è¡Œæ–¹æ³•ï¼Œä¿æŒå‘åŽå…¼å®¹æ€§ã€‚
    
    è‡ªåŠ¨çŠ¶æ€ç®¡ç†ï¼š
    - INITIALIZED çŠ¶æ€ï¼šè°ƒç”¨ prepare() ç„¶åŽ run()
    - CONFIGURED çŠ¶æ€ï¼šç›´æŽ¥è°ƒç”¨ run()
    - å…¶ä»–çŠ¶æ€ï¼šæŠ›å‡º ValueError
    
    æ³¨æ„ï¼šæ­¤æ–¹æ³•å·²å¼ƒç”¨ï¼Œå»ºè®®ä½¿ç”¨ run() æ–¹æ³•èŽ·å¾—æ›´å¥½çš„
          çŠ¶æ€ç®¡ç†å’Œæ›´æ¸…æ™°çš„è¯­ä¹‰ã€‚
    
    Returns:
        ç®¡é“æ‰§è¡Œç»“æžœ
    """
```

## ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬ä½¿ç”¨ï¼ˆæŽ¨èï¼‰

```python
from xpertcorpus.modules.frameworks import XFramework_PT

# æœ€ç®€å•çš„ä½¿ç”¨æ–¹å¼ - è‡ªåŠ¨çŠ¶æ€ç®¡ç†
framework = XFramework_PT(
    input_file="./corpus_directory",
    output_dir="./output",
    max_workers=2
)

# ä¸€é”®æ‰§è¡Œ - è‡ªåŠ¨å‡†å¤‡å’Œè¿è¡Œ
results = framework.run()  # è‡ªåŠ¨è°ƒç”¨ prepare() ç„¶åŽæ‰§è¡Œ

print(f"å¤„ç†å®Œæˆï¼è¾“å‡ºè·¯å¾„: {results['output_path']}")
```

### æ‰‹åŠ¨æŽ§åˆ¶ï¼ˆå¯é€‰ï¼‰

```python
from xpertcorpus.modules.frameworks import XFramework_PT

# æ‰‹åŠ¨æŽ§åˆ¶ç”Ÿå‘½å‘¨æœŸ
framework = XFramework_PT(
    input_file="./corpus_directory",
    output_dir="./output",
    max_workers=2
)

# æ‰‹åŠ¨å‡†å¤‡ç»„ä»¶
framework.prepare()

# æ‰§è¡Œå¤„ç†ç®¡é“
results = framework.run()

print(f"å¤„ç†å®Œæˆï¼è¾“å‡ºè·¯å¾„: {results['output_path']}")
```

### é«˜çº§é…ç½®ä½¿ç”¨

```python
# è¯¦ç»†é…ç½®
config = {
    "text_splitter": {
        "chunk_size": 2048,
        "chunk_overlap": 512,
        "split_method": "semantic",
        "min_tokens_per_chunk": 50
    },
    "storage": {
        "enable_compression": True,
        "validate_on_write": True
    },
    "processing": {
        "supported_extensions": [".txt", ".md", ".rst", ".doc"],
        "exclude_patterns": [".bak", ".tmp", ".cache"]
    }
}

framework = XFramework_PT(
    input_file="large_corpus/",
    output_dir="./processed_output",
    max_workers=8,
    limit=10000,  # å¤„ç†å‰10000ä¸ªæ–‡ä»¶
    config=config
)

# æ·»åŠ é’©å­ç›‘æŽ§è¿›åº¦
def progress_hook(framework):
    metrics = framework.get_metrics()
    print(f"å·²å¤„ç†: {metrics['files_processed']} æ–‡ä»¶")

framework.add_hook("after_run", progress_hook)

# æ‰§è¡Œå¤„ç†
results = framework.run()
```

### é”™è¯¯å¤„ç†å’Œæ¢å¤

```python
import os
from xpertcorpus.modules.frameworks import XFramework_PT

def safe_process_corpus(input_path, output_path):
    """å®‰å…¨å¤„ç†è¯­æ–™çš„å°è£…å‡½æ•°"""
    framework = XFramework_PT(
        input_file=input_path,
        output_dir=output_path,
        max_workers=4
    )
    
    try:
        # æ£€æŸ¥è¾“å…¥
        if not os.path.exists(input_path):
            raise FileNotFoundError(f"è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {input_path}")
        
        # å‡†å¤‡æ¡†æž¶
        framework.prepare()
        
        # æ‰§è¡Œå¤„ç†
        results = framework.run()
        
        # éªŒè¯ç»“æžœ
        if results.get("final_output_key"):
            print("âœ… å¤„ç†æˆåŠŸå®Œæˆ")
            return results
        else:
            print("âš ï¸ å¤„ç†å®Œæˆä½†æ— è¾“å‡º")
            return None
            
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        
        # èŽ·å–é”™è¯¯ä¿¡æ¯
        error_info = framework.get_info()
        print(f"é”™è¯¯è¯¦æƒ…: {error_info}")
        
        # èŽ·å–å·²å¤„ç†çš„éƒ¨åˆ†
        metrics = framework.get_metrics()
        if metrics['files_processed'] > 0:
            print(f"å·²å¤„ç†æ–‡ä»¶: {metrics['files_processed']}")
            print(f"è¾“å‡ºç›®å½•: {framework.output_dir}")
        
        return None

# ä½¿ç”¨ç¤ºä¾‹
results = safe_process_corpus("./corpus", "./output")
```

### æ‰¹å¤„ç†æ¨¡å¼

```python
import glob
from pathlib import Path

def batch_process_directories(corpus_dirs, output_base):
    """æ‰¹é‡å¤„ç†å¤šä¸ªè¯­æ–™ç›®å½•"""
    results = []
    
    for corpus_dir in corpus_dirs:
        corpus_name = Path(corpus_dir).name
        output_dir = os.path.join(output_base, f"processed_{corpus_name}")
        
        print(f"å¤„ç†è¯­æ–™: {corpus_dir} -> {output_dir}")
        
        framework = XFramework_PT(
            input_file=corpus_dir,
            output_dir=output_dir,
            max_workers=2,
            config={
                "storage": {"enable_compression": True},
                "processing": {"supported_extensions": [".txt", ".md"]}
            }
        )
        
        try:
            framework.prepare()
            result = framework.run()
            results.append({
                "corpus": corpus_dir,
                "output": output_dir,
                "success": True,
                "metrics": framework.get_metrics(),
                "result": result
            })
            print(f"âœ… {corpus_name} å¤„ç†å®Œæˆ")
            
        except Exception as e:
            results.append({
                "corpus": corpus_dir,
                "output": output_dir,
                "success": False,
                "error": str(e)
            })
            print(f"âŒ {corpus_name} å¤„ç†å¤±è´¥: {e}")
    
    return results

# æ‰¹é‡å¤„ç†ç¤ºä¾‹
corpus_directories = glob.glob("./data/corpus_*")
batch_results = batch_process_directories(corpus_directories, "./batch_output")

# ç»Ÿè®¡ç»“æžœ
successful = sum(1 for r in batch_results if r["success"])
print(f"æ‰¹å¤„ç†å®Œæˆ: {successful}/{len(batch_results)} æˆåŠŸ")
```

## æ€§èƒ½ä¼˜åŒ–

### å¤šçº¿ç¨‹é…ç½®

```python
# CPUå¯†é›†åž‹ä»»åŠ¡ä¼˜åŒ–
import multiprocessing

cpu_count = multiprocessing.cpu_count()
framework = XFramework_PT(
    input_file="large_corpus/",
    max_workers=cpu_count - 1,  # ä¿ç•™ä¸€ä¸ªæ ¸å¿ƒç»™ç³»ç»Ÿ
    config={
        "processing": {"batch_size": 100},
        "storage": {"enable_compression": True}
    }
)
```

### å†…å­˜ä¼˜åŒ–

```python
# å¤§æ–‡ä»¶å¤„ç†ä¼˜åŒ–
config = {
    "text_splitter": {
        "chunk_size": 512,  # è¾ƒå°çš„å—å¤§å°
        "chunk_overlap": 100
    },
    "storage": {
        "enable_compression": True,  # å¯ç”¨åŽ‹ç¼©å‡å°‘ç£ç›˜å ç”¨
        "validate_on_write": False   # è·³è¿‡éªŒè¯æå‡é€Ÿåº¦
    }
}

framework = XFramework_PT(
    input_file="very_large_corpus/",
    config=config
)
results = framework.run()  # ä¸€é”®æ‰§è¡Œ
```

## æœ€ä½³å®žè·µ

### 1. çŠ¶æ€ç®¡ç†æœ€ä½³å®žè·µ

```python
# âœ… æŽ¨èï¼šç®€å•ç›´æŽ¥çš„ä½¿ç”¨æ–¹å¼
framework = XFramework_PT(input_file="data.jsonl")
results = framework.run()  # è‡ªåŠ¨å¤„ç†çŠ¶æ€

# âœ… æŽ¨èï¼šç›‘æŽ§çŠ¶æ€å˜åŒ–
framework = XFramework_PT(input_file="data.jsonl")
print(f"åˆå§‹çŠ¶æ€: {framework.get_state()}")  # INITIALIZED
results = framework.run()  # è‡ªåŠ¨ prepare() â†’ CONFIGURED â†’ RUNNING â†’ COMPLETED
print(f"æœ€ç»ˆçŠ¶æ€: {framework.get_state()}")  # COMPLETED

# âŒ ä¸æŽ¨èï¼šæ‰‹åŠ¨ç®¡ç†ç®€å•æƒ…å†µ
framework = XFramework_PT(input_file="data.jsonl")
framework.prepare()  # å¯¹äºŽç®€å•ä½¿ç”¨æ˜¯å¤šä½™çš„
results = framework.run()

# âœ… æŽ¨èï¼šé”™è¯¯å¤„ç†å’ŒçŠ¶æ€é‡ç½®
try:
    results = framework.run()
except Exception as e:
    print(f"æ‰§è¡Œå¤±è´¥: {e}")
    framework.reset()  # é‡ç½®åˆ° INITIALIZED çŠ¶æ€
    # å¯ä»¥é‡æ–°å°è¯•æˆ–ä¿®æ”¹é…ç½®
```

### 2. è¾“å…¥æ•°æ®å‡†å¤‡

```python
# æ£€æŸ¥è¾“å…¥æ•°æ®è´¨é‡
def validate_input_corpus(corpus_path):
    """éªŒè¯è¾“å…¥è¯­æ–™çš„è´¨é‡"""
    if os.path.isdir(corpus_path):
        # æ£€æŸ¥æ–‡ä»¶æ•°é‡
        file_count = len([f for f in os.listdir(corpus_path) 
                         if f.endswith(('.txt', '.md'))])
        print(f"å‘çŽ° {file_count} ä¸ªæ–‡æœ¬æ–‡ä»¶")
        
        if file_count == 0:
            raise ValueError("è¯­æ–™ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°æ–‡æœ¬æ–‡ä»¶")
    
    elif os.path.isfile(corpus_path):
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(corpus_path)
        print(f"æ–‡ä»¶å¤§å°: {file_size / 1024 / 1024:.2f} MB")
        
        if file_size == 0:
            raise ValueError("è¾“å…¥æ–‡ä»¶ä¸ºç©º")
    
    else:
        raise FileNotFoundError(f"è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {corpus_path}")

# ä½¿ç”¨å‰éªŒè¯
validate_input_corpus("./corpus")
```

### 2. é…ç½®è°ƒä¼˜

```python
# æ ¹æ®æ•°æ®ç‰¹å¾è°ƒæ•´é…ç½®
def create_optimized_config(corpus_size, file_count):
    """æ ¹æ®è¯­æ–™è§„æ¨¡åˆ›å»ºä¼˜åŒ–é…ç½®"""
    config = {
        "text_splitter": {
            "chunk_size": 1024 if corpus_size > 1000000 else 512,
            "split_method": "semantic" if file_count < 1000 else "markdown"
        },
        "storage": {
            "enable_compression": corpus_size > 100000,
            "validate_on_write": file_count < 10000
        }
    }
    return config
```

### 3. ç›‘æŽ§å’Œæ—¥å¿—

```python
# æ·»åŠ è¯¦ç»†ç›‘æŽ§
def add_monitoring_hooks(framework):
    """æ·»åŠ ç›‘æŽ§é’©å­"""
    
    def on_start(fw):
        print(f"ðŸš€ å¼€å§‹å¤„ç†: {fw.input_file}")
        
    def on_progress(fw):
        metrics = fw.get_metrics()
        print(f"ðŸ“Š è¿›åº¦æ›´æ–°: {metrics}")
        
    def on_complete(fw):
        metrics = fw.get_metrics()
        print(f"âœ… å¤„ç†å®Œæˆï¼Œè€—æ—¶: {metrics['total_processing_time']:.2f}s")
        
    def on_error(fw, error):
        print(f"âŒ å¤„ç†å‡ºé”™: {error}")
        
    framework.add_hook("before_run", on_start)
    framework.add_hook("after_run", on_complete)
    framework.add_hook("on_error", on_error)

# ä½¿ç”¨ç›‘æŽ§
framework = XFramework_PT(input_file="corpus/")
add_monitoring_hooks(framework)
```

## æ•…éšœæŽ’é™¤

### å¸¸è§é—®é¢˜

#### 1. å†…å­˜ä¸è¶³
```python
# è§£å†³æ–¹æ¡ˆï¼šå‡å°‘æ‰¹å¤„ç†å¤§å°å’Œå—å¤§å°
config = {
    "text_splitter": {"chunk_size": 256},
    "processing": {"batch_size": 50}
}
```

#### 2. å¤„ç†é€Ÿåº¦æ…¢
```python
# è§£å†³æ–¹æ¡ˆï¼šå¢žåŠ çº¿ç¨‹æ•°ï¼Œç¦ç”¨éªŒè¯
framework = XFramework_PT(
    input_file="corpus/",
    max_workers=8,
    config={"storage": {"validate_on_write": False}}
)
```

#### 3. è¾“å‡ºæ–‡ä»¶ä¸ºç©º
```python
# æ£€æŸ¥è¾“å…¥æ•°æ®æ ¼å¼
framework.get_pipeline_info()  # æŸ¥çœ‹å¤„ç†çŠ¶æ€
```

---

**ç‰ˆæœ¬**: v1.0.0  
**æœ€åŽæ›´æ–°**: 2025-08-13  
**å…¼å®¹æ€§**: Python 3.10+ 